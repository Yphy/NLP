{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainig examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of trainig examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['From', 'a', 'modern', 'sensibility', ',', 'it', \"'s\", 'sometimes', 'hard', 'to', 'watch', 'older', 'films', '.', 'It', \"'s\", 'annoying', 'to', 'have', 'to', 'watch', 'the', 'stereotypical', 'wallflower', 'librarian', 'have', 'to', 'take', 'off', 'her', 'glasses', 'and', 'become', 'pretty', 'and', 'stupid', 'to', 'win', 'a', 'man', '.', 'Especially', 'such', 'a', 'shallow', 'and', 'inconstant', 'man', '.', 'He', \"'s\", 'obviously', 'a', 'player', '(', 'I', 'would', \"n't\", 'trust', 'him', 'to', 'stay', 'true', 'to', 'her', ')', 'who', 'does', \"n't\", 'want', 'to', 'settle', 'down', ',', 'who', 'only', 'looks', 'at', 'dumb', 'attractive', 'women', 'and', 'always', 'calls', 'them', '\"', 'baby', '\"', '(', 'ick', '!', ')', '.', 'Even', 'after', 'she', 'totally', 'changes', 'her', 'appearance', 'and', 'her', 'life', 'for', 'him', ',', 'he', 'only', 'goes', 'to', 'her', 'after', 'he', \"'s\", '(', 'supposedly', ')', 'rejected', 'by', 'another', 'woman', 'and', 'learns', 'that', 'Connie', 'spent', 'all', 'her', 'money', 'renovating', 'a', 'boat', 'for', 'him', '.', 'I', 'wanted', 'her', 'to', 'stand', 'up', 'to', 'him', ',', 'not', 'pathetically', 'chase', 'after', 'him', '!', 'His', 'sudden', 'conversion', 'within', 'a', 'few', 'minutes', 'was', 'totally', 'unrealistic', 'and', 'did', 'not', 'work', 'for', 'me.<br', '/><br', '/>Apart', 'from', 'that', 'subplot', ',', 'I', 'did', 'like', 'the', 'movie', '.', 'How', 'can', 'you', 'not', 'like', 'sailors', 'dancing', 'with', 'each', 'other', '?', '!', '(', 'You', 'can', 'tell', 'they', 'were', 'from', 'San', 'Francisco', '....', ';D', ')', 'The', '\"', 'rehearsal', '\"', 'dance', 'was', 'great', ',', 'watching', 'Ginger', 'Rogers', 'purposefully', 'fall', 'in', 'and', 'out', 'of', 'the', '\"', 'correct', 'steps', '\"', 'was', 'great', '.', 'The', 'last', 'dance', 'scene', '\"', 'Face', 'the', 'Music', '\"', 'with', 'the', 'beautiful', 'costumes', 'and', 'the', 'art', 'deco', 'set', 'was', 'beautiful', '.', 'And', 'I', 'really', 'enjoyed', '\"', 'We', 'Saw', 'the', 'Sea', '\"', '(', 'though', 'they', 'did', 'use', 'it', 'a', 'few', 'too', 'many', 'times', ',', 'as', 'if', 'they', 'realized', 'it', 'was', 'their', 'best', 'song', ')', '.', '<', 'br', '/><br', '/>Anyway', ',', 'the', 'plot', 'was', 'a', 'bit', 'weak', ',', 'like', 'most', 'musicals', '(', 'IMO', ')', '-', 'and', 'the', 'songs', 'were', 'OK', ',', 'but', 'the', 'dancing', 'was', 'worth', 'watching', 'the', 'film', 'for', '.', 'I', 'wish', 'they', 'could', 'have', 'showed', 'some', 'shots', 'of', 'San', 'Francisco', 'since', 'that', 'was', 'were', 'the', 'film', 'was', 'supposedly', 'set.<br', '/><br', '/>It', \"'s\", 'also', 'weird', 'to', 'see', 'such', 'a', 'lighthearted', 'naval', 'film', 'with', 'the', 'knowledge', 'of', 'what', 'Hitler', 'was', 'already', 'doing', 'at', 'that', 'time', '.', 'I', 'have', 'to', 'try', 'to', 'suspend', 'all', 'knowledge', 'to', 'submerge', 'myself', 'into', 'a', 'made', 'up', 'fantasy', 'land', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 17500\n",
      "Number of validation examples: 7500\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 25002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 201490), (',', 191070), ('.', 164685), ('and', 109019), ('a', 108721), ('of', 100582), ('to', 93295), ('is', 76021), ('in', 61323), ('I', 53792), ('it', 53054), ('that', 49008), ('\"', 43992), (\"'s\", 43023), ('this', 42179), ('-', 36787), ('/><br', 35349), ('was', 34977), ('as', 30340), ('with', 29854)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'neg': 0, 'pos': 1})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "\n",
    "__init__ 안에 모듈의 레이어를 정의한다. 세 개의 층은 embedding layer,\n",
    "RNN, 그리고 a linear layer이다. 모든 레이어들에는 특별히 정의하지 않은 한\n",
    "난수값으로 설정된 파라미터들이 있다. 임베딩 레이어는 sparse한 one-hot vector를 dense한 임베딩 벡터로 변환하는데 사용된다. 이 임베딩 레이어는 single fully connected layer이다. RNN의 input 차원을 줄일 뿐만 아니라 리뷰에서 비슷한 감성을 가지고있다고 판단되는 단어들의 theory를 dense한 벡터공간에 매핑시킨다. \n",
    "RNN 레이어에서는 one-hot벡터가 임베딩된 dense한 벡터를 가지고 이전의 ht-1에서 다음 hidden state인 ht를 계산하는데 RNN을 사용한다.\n",
    "마지막으로 linear layer가 hidden state를 계산하고 fully connected 된\n",
    "$f(h_T)$,를 통해서 ouput dimention으로 변환이된다.(?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward method란 이런 모델에 샘플을 투입하는 방식이다.\n",
    "각각의 배치인 text는 텐서의 사이즈 [sentence length, batch size]이다.\n",
    "이것은 내부의 각각 단어들이 one-hot벡터로 변환된 문장들의 배치이다.\n",
    "원핫벡터들때문에 텐서는 다른차원이 필요하지만 pytorch는 간편하게 원핫벡터를 인덱스 값으로 저장한다 즉, 한 문장을 표현하는 텐서는 그 문장 안의 각각의 토큰들의 인덱스들의 텐서와 같다. 토큰들의 리스트를 인덱스의 리스트로 변환하는 작업을 numericalizing이라고 한다. \n",
    "인풋 배치는 임베딩 레이어를 통해서 임베딩 되고, 이게 문장들의 dense한 벡터를 나타내게된다. 임베딩된건 텐서의 사이즈 [sentence length, batch size, embedding dim]이다.\n",
    "\n",
    "이제 임베딩 된 것들이 RNN을 통해 들어가게 된다. 몇몇 프레임워크들에서는 초기 히든 레이어를 직접 RNN에 넣어야 하지만 파이토치에서는 만약 초기 히든레이어의 설정값이 주어지지 않는다면 모든 텐서들을 0으로 간주한다.\n",
    "\n",
    "RNN은 [sentence length,batch size, hidden dim]의 output size 와 hidden of size인 [1, batch size, hidden dim]의 2개의 텐서를 반환한다.\n",
    "output은 모든 연속된 시간의 hidden state의 연쇄인 반면 hidden은 단지 마지막 hidden state이다. 우리는 이를 assert statement를 통해서 증명한다. 사이즈 하나의 차원 하나를 줄이기 위해서 squeeze 방법을 쓰는 것을 주목하라.\n",
    "마지막으로 마지막의 hidden state인 hidden을 선형 레이어 fc를 통과시켜 예측값을 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 RNN 클래스의 인스턴스가 만들어졌다.\n",
    "입력 차원은 원핫 벡터의 차원들과 같고 이는 단어의 사이즈와 같다.\n",
    "임베딩 차원은 dense한 단어들의 벡터의 사이즈와 같다. 이는 보통 50-250 개의 차원들이나\n",
    "보통 단어의 사이즈에 따라서 다르다.\n",
    "hidden dimention은 hidden states의 차원과 같다. 보통 100에서 500개의 차원들이나 \n",
    "단어의 사이즈나 밀집된 벡터의 크기나 일의 복잡성에 따라 달라진다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 모델이 얼마나 많은 학습가능한 매개변수들을 가지고 있는지 알려주는 함수를 만들어 다른모델들의 매개변수의 수와 비교할수 있게 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,592,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "우선 옵티마이저를 생성한다. 여기에는 모듈의 매개변수들을 업데이트 할 수 있는 알고리즘이 있다. 여기서, 우리는 stochastic gradient descent를 이용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 손실 함수를 살펴보자. 파이토치에서는 이걸 표준으로 부른다.\n",
    "여기서 손실 함수는 binary cross entropy with logits을 사용한다.\n",
    "\n",
    "사용한 모델은 현재 고정되지않은 숫자를 아웃풋으로 낸다. 우리의 레이블은 0 또는 1이여야 하기 때문에 우리는 예측값을 0에서 1사이의 숫자로 한정해야 한다. 따라서 시그모이드 또는 로지스틱 함수를 사용하기로 한다.\n",
    "\n",
    "그리고 이진 교차 엔트로피를 사용하여 손실을 계산하기 위해 bound scalar을 사용한다.\n",
    "\n",
    "BCEWithLogitsLoss criterion은 시그모이드와 이진 교차엔트로피 방법을 모두 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".to를 사용함으로써 모델과 criterion을 GPU에 실을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 criterion 함수는 손실을 계산하지만 정확도를 계산하기위해 함수를 만들 필요가 있다.\n",
    "이 함수는 처음에 예측값들을 시그모이드 층을 통하여 통과시키고 값을 0과 1 사이로 압축시키고\n",
    "그걸 근접한 정수에 배치시킨다. 0.5에서 1 사이의 값은 긍정으로 분류되고 나머지는 부정이다.\n",
    "\n",
    "그다음 얼마나 근사된 예측치가 실제 레이블과 동일한지 계산할 수 있고 배치를 통하여 평균을\n",
    "낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this\n",
    "    returns 0.8, NOT8\n",
    "    \"\"\"\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 함수는 한 배치에 한번씩 돌면서 모든 샘플들을 반복한다.\n",
    "model.train()은 모델을 트레이닝 모드에 놓는데 사용되며 드롭아웃과 배치 정규화를 사용한다. 비록 이 모델에서 이들을 사용하진 않지만, 포함시켜보는것도 좋은 연습이 된다.\n",
    "\n",
    "각각의 배치마다 우리는 처음에 경사를 0으로만든다. 한 모델 안의 각각의 매개변수들은 criterion에 의해서 계산된 경사값을 grad 특성에 가지고 있다. 파이토치는 이 경사들을 마지막 경사 계산을 통해 자동적으로 제거하거나 0으로만들지 않으므로 수동으로 0으로 만들어야 한다.\n",
    "\n",
    "그다음으로 문장들의 배치인 batch.text를 모델에 실어야한다. 그렇다고 model.forward(batch.text)를 할 필요는 없다. 예측값들이 초기에 [batch size,1]이고 차원의 크기를 1로 줄여야하기 때문에 squeeze가 필요하다.\n",
    "\n",
    "손실과 정확도는 예측값과 레이블들,batch.label을 사용하여 손실이 모든 샘플들의 배치를 돌면서 평균낸 값으로 계산된다. 각각의 매개변수들의 경사값은 loss.backward()를 통하여 계산되고 optimizer.step()의 옵티마이저 알고리즘을 통하여 업데이트된다.\n",
    "\n",
    "손실과 정확성은 에폭을 돌면서 축적되고 .item()이 하나의 값을 가지고 있는 텐서로부터 스칼라 값을 추출하기 위해 사용된다.\n",
    "\n",
    "마지막으로, 에폭을돌면서 평균된 손실과 정확도값을 반환한다. 이터레이터의 길이는 이터레이터 안의 배치들의 수와 같다.\n",
    "\n",
    "LABEL field를 초기화할 때 우리는 토치값을 실수로 고정한다. 이는 왜냐하면 우리 criterion은 input값을 FloatTensor로 여기는 반면 TorchText는 LongTensor를 디폴트 값으로 가지기 때문이다. 대안은 criterion에 batch.label을 쓰는 대신에 train 함수를 batch.label.float()에 통과시켜 변환하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval()는 모델을 evaluation mode에 넣고 드롭아웃과 배치 정규화를 사용한다.\n",
    "또다시 이 모델에서 사용하진 않지만 좋은 연습이도리거다\n",
    "With no_grad()에서는 파이토치 연산에서 경사값 계산이 되지 않으므로 메모리 소모가 적어\n",
    "연산 속도를 늘릴 수 있다.\n",
    "나머지 함수는 train함수와 같다. optimizer.zero_grad(),loss.backward(), \n",
    "optimizer.step()을 제거함으로써 평가도중 모델의 파라미터들을 제거하진 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 모델들 간의 트레이닝 시간을 비교하기 위해서 한 에폭을 도는데 시간이 얼마나 걸리는지\n",
    "측정하는 함수를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time_):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 멀티플 에폭을 돌면서 모델을 트레인시키고, 에폭은 training , validation sets를 모두 완전히 통과한다.\n",
    "\n",
    "각각의 에폭에서, 만약 validation loss가 지금까지 본 것중에 가장 적다면 , 그 모델의 파라미터들을 저장해서 트레이닝이 끝난 후에 테스트 셋에다 그 모델을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.11%\n",
      "\t Val. Loss: 0.696 |  Val. Acc: 48.95%\n",
      "Epoch: 02 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.87%\n",
      "\t Val. Loss: 0.695 |  Val. Acc: 50.46%\n",
      "Epoch: 03 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.693 | Train Acc: 49.28%\n",
      "\t Val. Loss: 0.696 |  Val. Acc: 48.97%\n",
      "Epoch: 04 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.17%\n",
      "\t Val. Loss: 0.696 |  Val. Acc: 48.97%\n",
      "Epoch: 05 | Epoch Time: 0m 48s\n",
      "\tTrain Loss: 0.693 | Train Acc: 50.14%\n",
      "\t Val. Loss: 0.695 |  Val. Acc: 48.90%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 결과를 보고 손실이 실제로 잘 줄어들지 않았고 정확도가 떨어진다는 것을 알 수 있다.\n",
    "이것은 모델과 관련된 몇몇 문제가 있고 이를 다음 노트에서 개선할 것이다.\n",
    "\n",
    "마지막으로 테스트 셋에대한 손실과 정확도를 볼 것인데 이는 가장 좋은 validation loss 로 부터 얻어낸 매개변수들을 사용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.677) |  Test Acc: 61.85%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f}) |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nexp steps\n",
    "\n",
    "다음 notebook에서 정확성을 향상시키기 위해 다룰것들은 다음과 같다\n",
    "\n",
    "packed padded sequences\n",
    "pre-trained word embeddings\n",
    "different RNN architecture\n",
    "bidirectional RNN\n",
    "multi-layer RNN\n",
    "regularization\n",
    "a different optimizer\n",
    "\n",
    "이들은 ~84% 의 정확성 향상까지 도와줄 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine_3.6",
   "language": "python",
   "name": "engine_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
