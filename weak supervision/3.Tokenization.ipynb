{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mecab = MeCab.Tagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한국어 형태소 분석기인 mecab을 가지고 Tokenization을 해주었습니다. 명사만 따로 추출하여 wordcloud로 확인하기 위해서 명사를 따로 추출했고 토큰화가 완료된 문서들을 str_token의 형태로 추가했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_morphs(text):   # konlpy의 mecab output 형태와 같게 만들어주는 함수\n",
    "    morphs = []\n",
    "    \n",
    "    pattern = re.compile(\".*\\t[A-Z]+\") \n",
    "    \n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "        \n",
    "    for token in temp:\n",
    "        morphs.append(token[0])\n",
    "    \n",
    "    return morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_nouns(text):#명사만 반환\n",
    "    morphs = []\n",
    "    pattern = re.compile(\".*\\t[A-Z]+\")\n",
    "    temp = [tuple(pattern.match(token).group(0).split(\"\\t\")) for token in mecab.parse(text).splitlines()[:-1]]\n",
    "    for token in temp:\n",
    "        if token[1] == 'NNG':\n",
    "            morphs.append(token[0])\n",
    "    return morphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/crawling/preprocessed/df.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document): #특수문자 기본 전처리 함수\n",
    "    docu = []\n",
    "    for doc in document:\n",
    "        doc = re.sub('[^가-힣0-9\\s.]','',doc)\n",
    "        doc = re.sub('[-=+,#/\\?:^$@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','',doc)\n",
    "        doc = re.sub('[0-9]+','num',doc) #숫자를 special token num으로 치환\n",
    "        pattern = re.compile(r'\\s+') #중복띄어쓰기 제거\n",
    "        doc = re.sub(pattern,' ',doc)\n",
    "        doc = doc.replace('\\xa0','') \n",
    "        doc = doc.replace('\\n','')\n",
    "        docu.append(doc)\n",
    "\n",
    "    return docu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ls = [x for x in df['str']]\n",
    "corrected_ls = preprocessing(str_ls)\n",
    "df['str'] = corrected_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = [mecab_morphs(x) for x in df['str']]\n",
    "kl = [] #리스트안에 형태소분석된 토큰들이 들어있는 형태라서 str로 바꿔서 새 컬럼에 추가해준다\n",
    "for k in kk:\n",
    "    kl.append(' '.join(k))\n",
    "df['str_tokens'] = kl\n",
    "df = df.loc[:,('crp_nm','rpt_nm','rcp_no','rcp_dt','rmk','str','str_tokens')]\n",
    "\n",
    "nouns_ls = [mecab_nouns(x) for x in df['str']] #noun wordcloud용\n",
    "ke=[]\n",
    "for k in nouns_ls:\n",
    "    ke.append(' '.join(k))\n",
    "df['str_nouns'] = ke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcp_ls = df['rcp_no']  #연도 column 생성\n",
    "rcp_ls = list(map(str,rcp_ls))\n",
    "rcp__ls = []\n",
    "for i in rcp_ls:\n",
    "    rcp__ls.append(int(i[0:4]))\n",
    "df.insert(0,'연도',rcp__ls) \n",
    "\n",
    "ls = []\n",
    "for i in df.연도:\n",
    "    ls.append(str(i))\n",
    "title_ls = ls+df.crp_nm\n",
    "\n",
    "df_cosine =  df.copy()\n",
    "df_cosine.insert(0,'title',title_ls)  #새로운 title column 생성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
