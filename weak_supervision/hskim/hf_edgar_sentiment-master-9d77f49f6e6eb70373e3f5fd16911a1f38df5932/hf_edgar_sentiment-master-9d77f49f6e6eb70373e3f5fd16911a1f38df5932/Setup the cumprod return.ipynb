{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "TqdmDeprecationWarning: Please use `tqdm.pandas(...)` instead of `tqdm_pandas(tqdm(...))`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "tqdm_pandas(tqdm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(\"data/result_df.csv\",chunksize=100000,usecols=['path'],\\\n",
    "                      dtype = {\"path\" : \"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(df_iter,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = \"/mnt/processed/edgar_footnote_partition_indexing/word_index/\"\n",
    "path_ls = []\n",
    "year_list = ['2010','2011','2012','2013']\n",
    "\n",
    "for year in year_list : \n",
    "    year_dir = os.path.join(root_dir,year)\n",
    "    month_list = sorted(os.listdir(year_dir))\n",
    "    for month in month_list : \n",
    "        month_dir = os.path.join(year_dir,month)\n",
    "        path_ls.append(os.path.join(month_dir,'item7.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "for idx,fname in enumerate(path_ls) : \n",
    "    chunk = pd.read_pickle(fname)[['HFSID','UPDATED_DAY','path']]\n",
    "    result_df = pd.concat([result_df,chunk],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_df['path'] = result_df.path.apply(lambda x : x.replace(\"locdisk\",'mnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df = pd.merge(df,result_df,on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_df.to_csv(\"data/merge_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../SUBMIT/')\n",
    "from PKGS import us_starter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/lib/python2.7/site-packages/numba/errors.py:102: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "univ1000,univ1000_id_list,price_return,sector,industry,sub_industry,date_list = \\\n",
    "us_starter.starter(20100101,20140101,'1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_df = pd.DataFrame(price_return,date_list,univ1000_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_df = merge_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(di,ii,date) : \n",
    "    di_start_idx = np.searchsorted(date_list,di,'right')-1\n",
    "    di_start = date_list[di_start_idx]\n",
    "    di_end = date_list[di_start_idx+date]\n",
    "    \n",
    "    try : \n",
    "        series = return_df.loc[:,ii]        \n",
    "    except : \n",
    "        return np.nan\n",
    "    val = (series.loc[di_start:di_end] + 1).cumprod().iloc[-1]\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_df['RETURN100'] = unique_df.apply(lambda x : search(x['UPDATED_DAY'],x['HFSID'],100),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_df.to_csv(\"data/return_df.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(\"data/groupby_df.csv\")\n",
    "label_df.rename(columns={'1':'SCORE'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETURN5</th>\n",
       "      <th>RETURN10</th>\n",
       "      <th>RETURN20</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RETURN5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811281</td>\n",
       "      <td>0.657739</td>\n",
       "      <td>-0.042361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETURN10</th>\n",
       "      <td>0.811281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790621</td>\n",
       "      <td>-0.029953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETURN20</th>\n",
       "      <td>0.657739</td>\n",
       "      <td>0.790621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCORE</th>\n",
       "      <td>-0.042361</td>\n",
       "      <td>-0.029953</td>\n",
       "      <td>-0.020183</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RETURN5  RETURN10  RETURN20     SCORE\n",
       "RETURN5   1.000000  0.811281  0.657739 -0.042361\n",
       "RETURN10  0.811281  1.000000  0.790621 -0.029953\n",
       "RETURN20  0.657739  0.790621  1.000000 -0.020183\n",
       "SCORE    -0.042361 -0.029953 -0.020183  1.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(unique_df,label_df,on='path')[['RETURN5','RETURN10','RETURN20','SCORE']].dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv(\"data/label_df.csv\")\n",
    "del tmp_df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df = pd.merge(tmp_df,unique_df[['path','HFSID','UPDATED_DAY']],on='path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_df.to_csv('total_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groupby_df = \\\n",
    "total_df.groupby('path').agg({'score':'mean','vader':'mean','HFSID':'median'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupby_df.to_csv('groupby_df.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
