{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Updated Sentiment Analysis\n",
    "\n",
    "이전 노트북에서 감성분석의 기본적인 것들을 살펴보았고 여기서는 \n",
    "다음의 것들에 대한 결과를 살펴본다\n",
    "\n",
    "packed padded sequences \n",
    "pre-trained word embeddings \n",
    "different RNN architecture\n",
    "bidirectional RNN\n",
    "multi-layer RNN\n",
    "regularization\n",
    "a different optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data\n",
    "\n",
    "이전까지와 같이 시드를 배정하고 Fields를 정의하고 train/valid/test 셋을 분리할 것이다. \n",
    "RNN이 오직 우리 시퀀스에서 패딩되지 않은 원소만 계산하게 하기 위해서 packed padded sequence를 사용할것이고 패딩된 부분에 대해서는 제로 텐서로 만들 것이다. packed padded sequence를 사용하기 위해서는 RNN에 실제문장길이를 입력해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True) #include_lengths가 추가된 부분\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDb dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training set으로부터 validation set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "이제 pre-trained워드 임베딩을 사용하자. 워드임베딩을 랜덤하게 하는게 아니라 사전 학습된 백터들로 하는 것이다. 이러한 벡터들은 우리가 원하는 벡터를 골라서 build_vocab를 통하면서 특정지어진다.\n",
    "\n",
    "여기서, 우리는 glove.6B.100d 벡터를 사용한다. 6B는 사전학습된 토큰의 수가 6백만이라는 것이고 100d는 벡터들이 100차원이라는 것을 의미한다.\n",
    "\n",
    "사전 학습된 벡터들은 이미 벡터 스페이스에 \"terrible\", \"awful\", \"dreadful\"과 같은 비슷한 의미를 가진 단어들이 근처에 모여있다는 것이다. unk_init~.normal을 통해  랜덤값이 아닌 가우시안 분포를 통해서 단어들이 initialize된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:59, 4.79MB/s]                               \n",
      "100%|█████████▉| 399854/400000 [00:30<00:00, 22703.64it/s]"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 25_000\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 max_size = MAX_VOCAB_SIZE,\n",
    "                 vectors = \"glove.6B.100d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True, #배치안의 모든 텐서들이 길이를 기준으로 분리됨\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "## Different RNN Architectur\n",
    "\n",
    "Long Short-Term Memory(LSTM)이라고 불리는 RNN 아키텍처를 사용할 것이다.\n",
    "왜 LSTM이 RNN보다 낫냐. vanishing gradient problem때문이다. LSTM은 cell  $c$ 라고 불리는 recurrent state를 추가함으로써 LSTM의 메모리 역할을 하여 메모리중에서 정보의 흐름을 통제하는 다중 게이트의 기능을 한다. \n",
    "식으로 표현하자면 $$(h_t, c_t) = \\text{LSTM}(x_t, h_t, c_t)$$ 이다\n",
    "\n",
    "초기 셀 상태인 $c_0$는 초기 hidden state와 같이 모든 텐서가 0이다. 그러나 여전히 감성 예측은 오직 마지막 셀 상태 $\\hat{y}=f(h_T)$.가 아니라 hidden state를 가지고만 이뤄진다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNN\n",
    "\n",
    "양방향 RNN의 컨셉은 매우 간단하다. RNN이 문장의 단어들이 처음부터 끝까지 정방향의 과정을 거쳤다면 반대로 끝에서부터 시작하는 역방향 RNN이 존재하는 것이다. 정방향에서 $x_t$, 이면 역방향 RNN은 $x_{T-t+1}$.을 계산하고 있다.\n",
    "\n",
    "파이토치에서 정,역방향에서 계산된 텐서들은 각각 맨 위에 서로다른 단일 텐서로 쌓인다.\n",
    "우리는 감성 예측을 정방향, 그리고 역방향의 각각의 마지막 hidden state의 연쇄로 구하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer RNN\n",
    "\n",
    "deep RNN이라고도 불리는 Multi-layer RNN 또한 간단한 컨셉으로 이뤄진다. 기존의 일반 RNN에 추가하는것.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "비록 모델의 향상을 위한거지만 각각의 방법들은 모델에 매개변수들을 추가시켰다.\n",
    "매개변수의 수가 많아질수록 모델이 과적합(오버피팅)될 가능성이 커진다. 이를 해결하기 위해서 정규화를 사용한다. 더 특징적으로는 드롭아웃이라는 정규화 방법을 사용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Details\n",
    "\n",
    "우리는 모델에서 패드 토큰이 임베딩을 하면서 문장의 감성을 판단하는 데 있어서 중요하지 않은 것을 알기 때문에 패드토큰이 padding_idx로 임베딩 레이어를 통과하게 한다.\n",
    "\n",
    "RNN대신에 LSTM을 사용하기위해서 nn.LSTM을 쓴다. 또한 RNN이 output과 hidden state 를 출력했다면 LSTM은 output과 튜플형태의 hidden state 그리고 final cell state를 반환하는 것에 대해 주목해라.\n",
    "\n",
    "LSTM의 최종 hidden state가 정방향,역방향 요소를 모두 가지고있기때문에 나중에 연쇄될 것이지만, nn.Linear 층의 입력 사이즈는 은닉층의 두배이다.\n",
    "\n",
    "드롭아웃은 nn.Dropout을 시행하므로써 실행되며 드롭아웃 시키고 싶은 각각의 레이어들에 대한 정방향 방법에서 사용된다. 입력층과 출력층에서 드룹아웃을 절대 사용하면안된다.( 이 경우에는 text와 fc이다) 중간 층에서만 사용해야하고 LSTM에서는 한층의 은닉상태에서 다음 층의 은닉 상태로 가는데만 사용된다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        #unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * num directions]\n",
    "        #output over padding tokens are zero tensors\n",
    "        \n",
    "        #hidden = [num layers * num directions, batch size, hid dim]\n",
    "        #cell = [num layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        #and apply dropout\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 했던 것 과 같이, bidirectionality와 드롭아웃 가능성, 레이어의 수에 대한 논의와 매개변수를 적용하여 RNN클래스의 인스턴스를 만들 것이다.\n",
    "\n",
    "사전 학습된 벡터들이 모델에 로드되게 하기 위해서 EMBEDDING_DIM은 이전에 로드된 사전 학습된 Glove 벡터들과 동일하게 해야 한다.\n",
    "\n",
    "단어들에서 패드 토큰의 인덱스를 가져오며 실제 스트링이 <pad> 로 표기된 패트토큰의 특성을\n",
    "대표하게 해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = RNN(INPUT_DIM,\n",
    "            EMBEDDING_DIM,\n",
    "            HIDDEN_DIM,\n",
    "            OUTPUT_DIM,\n",
    "            N_LAYERS,\n",
    "            BIDIRECTIONAL,\n",
    "            DROPOUT,\n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델의 파라미터 수를 보여줄 것이다.\n",
    "기존 파라미터들의 수보다 두배 증가했음에 유의해라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 4,810,857 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 추가할 것은 사전에 학습된 단어 임베딩을 복사하여 모델의 임베딩 레이어에 넣는 것이다. filed의 vocab에서 임베딜을 검색하여 사이즈가 정확한지에 대하여 검색한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25002, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
       "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.1181,  0.5395,  0.1928,  ...,  0.3824, -0.7506, -0.3359],\n",
       "        [-0.6320,  0.2957,  0.2505,  ..., -0.0964, -0.2494,  0.3276],\n",
       "        [-0.1673, -0.5686,  0.2724,  ..., -0.9791,  0.1121,  0.3235]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<unk> 그리고 <pad> 토큰들이 사전 학습된 단어들 속에 있지 않기 때문에 vocab 을 만들 떄 unk_init을 사용한다. 이들 모두를 0으로 만드는 것이 선호되는데 어차피 감성에 대한 결정을 하는데 있어 의미있게 작용하지 않기 때문이다.\n",
    "\n",
    "이것은 임베딩 가중치 행렬의 열을 0으로 수동적으로 바꾸면서 진행된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [ 0.1181,  0.5395,  0.1928,  ...,  0.3824, -0.7506, -0.3359],\n",
      "        [-0.6320,  0.2957,  0.2505,  ..., -0.0964, -0.2494,  0.3276],\n",
      "        [-0.1673, -0.5686,  0.2724,  ..., -0.9791,  0.1121,  0.3235]])\n"
     ]
    }
   ],
   "source": [
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "변화된 것 한가지는 옵티마이저가 SGD 에서 Adam으로 바뀌는 것이다. SGD는 모든 파라미터들을 같은 learning rate로 업데이트 시킨다.\n",
    "\n",
    "SGD를 Adam 으로 바꾸기 위해서 우리는 간단히 optim.SGD를 optim.Adam으로 바꾸면 된다. 또한 아담은 초기 러닝레이트를 제공할 필요 없이 파이토치가 값을 매겨준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "나머지 모델 훈련과정은 다르지 않다.\n",
    "우리는 criterion을 정의하고 모델과 criterion을 gpu에 싣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 모델을 테스트 하기위해서 함수를 정의하는데 batch.text를 분리하는걸 기억한다.\n",
    "Note : 드롭아웃을 사용하기 때문에, model.eval()을 사용해 evaluating 하는동안 turn off 해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text, text_lengths = batch.text\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 에폭이 도는데 얼마나 걸리는지 알려주는 함수를 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습시킨다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.643 | Train Acc: 62.02%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 77.49%\n",
      "Epoch: 02 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.534 | Train Acc: 73.11%\n",
      "\t Val. Loss: 0.467 |  Val. Acc: 77.91%\n",
      "Epoch: 03 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.433 | Train Acc: 80.34%\n",
      "\t Val. Loss: 0.365 |  Val. Acc: 84.24%\n",
      "Epoch: 04 | Epoch Time: 0m 55s\n",
      "\tTrain Loss: 0.370 | Train Acc: 84.08%\n",
      "\t Val. Loss: 0.450 |  Val. Acc: 81.69%\n",
      "Epoch: 05 | Epoch Time: 0m 54s\n",
      "\tTrain Loss: 0.316 | Train Acc: 87.11%\n",
      "\t Val. Loss: 0.293 |  Val. Acc: 87.80%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 향상된 테스트 셋의 정확도를 살펴보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.307 | Test Acc: 87.29%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | \n",
    "      Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 부정적인 리뷰의 값이 0에 가깝고 긍정적인 리뷰가 1에 가까운 값이 나오도록 하고싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0074930922128260136"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is terrible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9873881936073303"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"This film is great\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "우리는 이제껏 영화 리뷰에 대한 감성 분석기를 만들었다! 다음 노트에서는 더 적은 파라미터들을 가지고 학습하여 비교적 정확성있고 빠른 모델을 만들도록 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engine_3.6",
   "language": "python",
   "name": "engine_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
